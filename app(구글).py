import streamlit as st
st.set_page_config(page_title="AI ë©´ì ‘ ì—ì´ì „íŠ¸", layout="wide")

import pandas as pd
import whisper
import av
import tempfile
import pdfplumber
import re
import numpy as np # NumPy ì„í¬íŠ¸
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode
import scipy.io.wavfile # SciPy wavfile ì„í¬íŠ¸

# Google Gemini API ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import google.generativeai as genai

# API í‚¤ ì„¤ì • (Streamlit secrets ì‚¬ìš©)
# st.secretsì— google.api_keyë¡œ ì €ì¥ëœ í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
try:
    genai.configure(api_key=st.secrets["google"]["api_key"])
    # ì‚¬ìš©í•  Gemini ëª¨ë¸ ì§€ì •
    # 'gemini-1.5-pro-latest' ë˜ëŠ” ë‹¤ë¥¸ ì•ˆì •í™” ë²„ì „ ì‚¬ìš©
    GEMINI_MODEL_NAME = "gemini-1.5-pro" # ë˜ëŠ” 'gemini-1.5-pro-latest'
except KeyError:
    st.error("Streamlit secretsì— 'google.api_key'ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()
except Exception as e:
    st.error(f"Gemini API ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()


@st.cache_resource
def load_whisper_model():
    """Whisper ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ìºì‹±í•©ë‹ˆë‹¤."""
    st.info("Whisper ëª¨ë¸ ë¡œë“œ ì¤‘ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...")
    model = whisper.load_model("base") # 'base', 'small', 'medium' ë“± ì„ íƒ ê°€ëŠ¥
    st.success("Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    return model

# Whisper ëª¨ë¸ ë¡œë“œ
whisper_model = load_whisper_model()


st.title("ğŸ¤ AI ë©´ì ‘ ì—ì´ì „íŠ¸")
st.info("ì§€ì›ì ì´ë ¥ì„œë¥¼ ë§¥ë½ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ê³ , PDF ê¸°ë°˜ ì§ˆë¬¸ì„ ìƒì„±í•˜ë©°, ìŒì„± ì‘ë‹µê¹Œì§€ ê¸°ë¡í•©ë‹ˆë‹¤.")

st.header("1ï¸âƒ£ íšŒì‚¬ ì •ë³´ ë° ì´ë ¥ì„œ ì—…ë¡œë“œ")
col1, col2 = st.columns(2)

with col1:
    core_pdfs = st.file_uploader("ğŸ¢ í•µì‹¬ ê°€ì¹˜ (PDF)", type=["pdf"], accept_multiple_files=True, key="core_uploader")
    persona_pdfs = st.file_uploader("ğŸ‘¤ ì¸ì¬ìƒ (PDF)", type=["pdf"], accept_multiple_files=True, key="persona_uploader")

with col2:
    jd_pdfs = st.file_uploader("ğŸ“ ì§ë¬´ ê¸°ìˆ ì„œ (PDF)", type=["pdf"], accept_multiple_files=True, key="jd_uploader")
    resume_pdfs = st.file_uploader("ğŸ“„ ì§€ì›ì ì´ë ¥ì„œ (PDF)", type=["pdf"], accept_multiple_files=True, key="resume_uploader")

def extract_pdf_text(files):
    """ì—…ë¡œë“œëœ PDF íŒŒì¼ë“¤ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    result = ""
    if files:
        for uploaded_file in files:
            # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ë˜ëŒë¦½ë‹ˆë‹¤ (Streamlit rerun ì‹œ í•„ìš”)
            uploaded_file.seek(0)
            try:
                with pdfplumber.open(uploaded_file) as pdf:
                    # ê° í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  í•©ì¹©ë‹ˆë‹¤.
                    page_texts = []
                    for page in pdf.pages:
                         text = page.extract_text()
                         if text:
                              page_texts.append(text)
                    result += "\n\n".join(page_texts) + "\n\n" # íŒŒì¼ ê°„ êµ¬ë¶„ì„ ìœ„í•´ ê³µë°± ì¶”ê°€
            except Exception as e:
                st.warning(f"PDF íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {uploaded_file.name} - {e}")
                result += f"\n\n[í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {uploaded_file.name}]\n\n"
    return result.strip() # ë§ˆì§€ë§‰ ê³µë°± ì œê±°

# LLMì˜ ì»¨í…ìŠ¤íŠ¸ ì°½ ì œí•œì„ ê³ ë ¤í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìë¦…ë‹ˆë‹¤.
# Gemini 1.5 ProëŠ” í° ì»¨í…ìŠ¤íŠ¸ë¥¼ ì§€ì›í•˜ì§€ë§Œ, API ë¹„ìš© ë° ì²˜ë¦¬ ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬
# ì ì ˆí•œ ê¸¸ì´ë¡œ ì¡°ì ˆí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” OpenAI ë•Œë³´ë‹¤ ì—¬ìœ  ìˆê²Œ ì¡ìŠµë‹ˆë‹¤.
def truncate_text(text, max_tokens=128000): # 128K í† í° ê¸°ì¤€ ì˜ˆì‹œ
    """í…ìŠ¤íŠ¸ë¥¼ í† í° ê¸°ì¤€ìœ¼ë¡œ ìë¦…ë‹ˆë‹¤ (ëŒ€ëµì ì¸ ê¸¸ì´)."""
    # ì‹¤ì œ í† í° ê³„ì‚°ì€ APIë¥¼ ì‚¬ìš©í•´ì•¼ ì •í™•í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê¸€ì ìˆ˜ë¡œ ëŒ€ëµ ì¶”ì •
    # í•œêµ­ì–´ëŠ” 1í† í°ë‹¹ ê¸€ì ìˆ˜ê°€ ì ìœ¼ë¯€ë¡œ, ë³´ìˆ˜ì ìœ¼ë¡œ ì ‘ê·¼
    # ì˜ˆë¥¼ ë“¤ì–´ 1í† í° = 1~2 ê¸€ìë¡œ ê°€ì •í•˜ê³ , 128000 í† í° * 1.5 ê¸€ì/í† í° = ì•½ 192000 ê¸€ì
    max_chars = int(max_tokens * 1.5) # ëŒ€ëµì ì¸ ê¸€ì ìˆ˜ ì œí•œ
    if len(text) > max_chars:
        st.warning(f"í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ì–´ {max_chars}ìë¡œ ì˜ëìŠµë‹ˆë‹¤.")
        return text[:max_chars] + "..." # ì˜ë ¸ìŒì„ í‘œì‹œ
    return text

st.header("2ï¸âƒ£ ì§ˆë¬¸ ìë™ ìƒì„± (AI ê¸°ë°˜)")
num_questions = st.slider("ì§ˆë¬¸ ìˆ˜", 1, 15, 5) # ì§ˆë¬¸ ìˆ˜ ë²”ìœ„ ë° ê¸°ë³¸ê°’ ì¡°ì •

if st.button("ğŸš€ ì§ˆë¬¸ ìƒì„±", key="generate_button"):
    with st.spinner("AIê°€ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        core_text = extract_pdf_text(core_pdfs)
        persona_text = extract_pdf_text(persona_pdfs)
        jd_text = extract_pdf_text(jd_pdfs)
        resume_text = extract_pdf_text(resume_pdfs)

        if not all([core_text, persona_text, jd_text, resume_text]):
            st.warning("ëª¨ë“  PDF í•­ëª©ì„ ì—…ë¡œë“œí•´ì•¼ ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            # Gemini 1.5 Proì˜ ëŒ€ìš©ëŸ‰ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì¢€ ë” ë§ì€ í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬
            # í•˜ì§€ë§Œ ë„ˆë¬´ ê¸¸ë©´ ë¹„ìš© ë° ì§€ì—°ì´ ë°œìƒí•˜ë¯€ë¡œ ì ì ˆí•œ ê¸¸ì´ ì¡°ì ˆ í•„ìš”
            # ì—¬ê¸°ì„œëŠ” truncate_text í•¨ìˆ˜ë¡œ ëŒ€ëµì ì¸ ìµœëŒ€ ê¸¸ì´ë¥¼ ì œí•œ
            truncated_core = truncate_text(core_text)
            truncated_persona = truncate_text(persona_text)
            truncated_jd = truncate_text(jd_text)
            truncated_resume = truncate_text(resume_text)


            prompt_text = f"""
            ë‹¹ì‹ ì€ ê¸°ì—…ì˜ ì‹œë‹ˆì–´ ì¸ì‚¬ë‹´ë‹¹ìì´ë©°, AI ë©´ì ‘ ì§ˆë¬¸ ìë™ ìƒì„± ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

            ì•„ë˜ 4ê°€ì§€ ë¬¸ì„œë¥¼ ì œê³µí•©ë‹ˆë‹¤:
            1. íšŒì‚¬ì˜ í•µì‹¬ ê°€ì¹˜ (Core Values)
            2. ì±„ìš© ì¸ì¬ìƒ (Ideal Persona)
            3. ì§ë¬´ ê¸°ìˆ ì„œ (Job Description)
            4. ì§€ì›ìì˜ ì´ë ¥ì„œ (Resume)

            ë‹¹ì‹ ì˜ ì—­í• ì€ ìœ„ 4ê°€ì§€ ë¬¸ì„œì˜ ë‚´ìš©ì„ ëª¨ë‘ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, íŠ¹íˆ ì´ë ¥ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§€ì›ìê°€ íšŒì‚¬ì˜ **í•µì‹¬ ê°€ì¹˜**, **ì¸ì¬ìƒ**, **ì§ë¬´ ìš”ê±´**ì— ì–¼ë§ˆë‚˜ ë¶€í•©í•˜ëŠ”ì§€ ê²€ì¦í•˜ê¸° ìœ„í•œ **ê²½í—˜ ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸**ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

            ---

            ğŸ“Œ ì§ˆë¬¸ ì„¤ê³„ ì§€ì¹¨:

            1. **ê²½í—˜ ê¸°ë°˜ ì§ˆë¬¸**ì„ ìƒì„±í•˜ì„¸ìš”. ë°˜ë“œì‹œ ì§€ì›ìì˜ **ì´ë ¥ì„œì— ì–¸ê¸‰ëœ êµ¬ì²´ì ì¸ ê³¼ê±° ê²½í—˜, í”„ë¡œì íŠ¸, í™œë™, ê²½ë ¥ ì‚¬í•­** ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸í•´ì•¼ í•©ë‹ˆë‹¤.
            2. ì§ˆë¬¸ì€ **í•µì‹¬ ê°€ì¹˜**, **ì¸ì¬ìƒ**, **ì§ë¬´ ìš”ê±´** ì¤‘ í•˜ë‚˜ ì´ìƒê³¼ ì—°ê´€ì‹œì¼œ, ì§€ì›ìì˜ ì—­ëŸ‰, í–‰ë™ ë°©ì‹, ê°€ì¹˜ê´€ ë“±ì„ ì‹¬ì¸µì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
            3. ì´ë ¥ì„œì˜ íŠ¹ì • ë¬¸ì¥, ê²½ë ¥ ë‚´ìš©, í‚¤ì›Œë“œ ë“±ì„ í™œìš©í•˜ì—¬ ë‹¤ë¥¸ ë¬¸ì„œë“¤ê³¼ **êµì°¨ ë¶„ì„**í•œ ê²°ê³¼ë¡œ ë„ì¶œëœ í†µì°°ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.
            4. ì§ˆë¬¸ì€ ëª…í™•í•˜ê³  ê°„ê²°í•´ì•¼ í•˜ë©°, ì§€ì›ìê°€ ìì‹ ì˜ ê²½í—˜ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ë„ë¡ ìœ ë„í•´ì•¼ í•©ë‹ˆë‹¤.
            5. í˜•ì‹ì€ ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤. ê° ì§ˆë¬¸ê³¼ ì§ˆë¬¸ ì˜ë„ë¥¼ êµ¬ë¶„í•˜ì—¬ ëª…í™•í•˜ê²Œ ì œì‹œí•´ì£¼ì„¸ìš”.

            ê° ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”:
            ===
            Q. [ì§ˆë¬¸ ë‚´ìš©]
            ì§ˆë¬¸ ì˜ë„: [ì´ ì§ˆë¬¸ì„ í†µí•´ ê²€ì¦í•˜ë ¤ëŠ” í•µì‹¬ ì—­ëŸ‰, ê²½í—˜ ë˜ëŠ” ê°€ì¹˜ê´€]
            ===

            ìš”ì²­ëœ ì§ˆë¬¸ ìˆ˜: {num_questions}ê°œ

            ---
            ì œê³µëœ ë¬¸ì„œ ë‚´ìš©:

            í•µì‹¬ ê°€ì¹˜:
            {truncated_core}

            ì¸ì¬ìƒ:
            {truncated_persona}

            JD:
            {truncated_jd}

            ì´ë ¥ì„œ:
            {truncated_resume}
            """

            try:
                # Gemini API í˜¸ì¶œ
                model = genai.GenerativeModel(GEMINI_MODEL_NAME)
                response = model.generate_content(
                    prompt_text,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.7, # ì°½ì˜ì„± ì¡°ì ˆ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë³´ìˆ˜ì )
                        max_output_tokens=2000 # ìƒì„±ë  ì‘ë‹µì˜ ìµœëŒ€ í† í° ìˆ˜ (ì§ˆë¬¸ ìˆ˜ì— ë”°ë¼ ì¡°ì ˆ)
                    )
                )

                # ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì˜¤ë¥˜ ì²˜ë¦¬
                if response and response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                    output = response.candidates[0].content.parts[0].text
                    if output:
                        st.session_state["questions_raw_output"] = output # ì›ë³¸ ì €ì¥
                        # ì‘ë‹µ íŒŒì‹± ë° ì§ˆë¬¸ ë°ì´í„° êµ¬ì¡°í™”
                        blocks = output.strip().split("===")
                        questions_data = []
                        for b in blocks:
                            lines = b.strip().split("\n")
                            q_line = next((l for l in lines if re.search(r"^[Qq][.:]\s*", l)), "") # 'Q.' ë˜ëŠ” 'Q:' ë“± ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì°¾ê¸°
                            intent_line = next((l for l in lines if "ì§ˆë¬¸ ì˜ë„:" in l), "")
                            if q_line:
                                questions_data.append({
                                    "question": re.sub(r"^[Qq][.:]\s*", "", q_line).strip(),
                                    "intent": intent_line.replace("ì§ˆë¬¸ ì˜ë„:", "").strip() if intent_line else "ì§ˆë¬¸ ì˜ë„ íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” ì—†ìŒ"
                                })
                        st.session_state["questions_data"] = questions_data # êµ¬ì¡°í™”ëœ ì§ˆë¬¸ ë°ì´í„° ì €ì¥

                        # ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ session_state ì´ˆê¸°í™” ë˜ëŠ” ë¶ˆëŸ¬ì˜¤ê¸°
                        if "interview_results_state" not in st.session_state:
                            st.session_state["interview_results_state"] = {}
                        # í˜„ì¬ ìƒì„±ëœ ì§ˆë¬¸ ìˆ˜ì— ë§ì¶° ê²°ê³¼ ìƒíƒœ ê³µê°„ í™•ë³´
                        for i in range(len(questions_data)):
                             if f"answer_{i}" not in st.session_state["interview_results_state"]:
                                  st.session_state["interview_results_state"][f"answer_{i}"] = ""
                             if f"comment_{i}" not in st.session_state["interview_results_state"]:
                                  st.session_state["interview_results_state"][f"comment_{i}"] = ""


                        st.success(f"ì§ˆë¬¸ ìƒì„± ì™„ë£Œ ({len(questions_data)}ê°œ)")
                    else:
                        st.error("AI ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. AIê°€ ìœ íš¨í•œ ë‚´ìš©ì„ ìƒì„±í•˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        st.session_state["questions_raw_output"] = ""
                        st.session_state["questions_data"] = []
                        st.session_state["interview_results_state"] = {} # ì´ˆê¸°í™”

                else:
                    st.error("AIë¡œë¶€í„° ìœ íš¨í•œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µì´ ì°¨ë‹¨ë˜ì—ˆê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    # ì‘ë‹µ ì°¨ë‹¨ ì •ë³´ í™•ì¸
                    if hasattr(response, 'prompt_feedback') and response.prompt_feedback:
                         st.warning(f"í”„ë¡¬í”„íŠ¸ í”¼ë“œë°±: {response.prompt_feedback}")
                    if hasattr(response, 'candidates') and response.candidates:
                        for candidate in response.candidates:
                            if hasattr(candidate, 'finish_reason'):
                                 st.warning(f"í›„ë³´ ì‘ë‹µ ì¢…ë£Œ ì´ìœ : {candidate.finish_reason}")
                            if hasattr(candidate, 'safety_ratings'):
                                 st.warning(f"ì•ˆì „ ë“±ê¸‰: {candidate.safety_ratings}")

                    st.session_state["questions_raw_output"] = ""
                    st.session_state["questions_data"] = []
                    st.session_state["interview_results_state"] = {} # ì´ˆê¸°í™”

            except Exception as e:
                st.error(f"AI ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.session_state["questions_raw_output"] = ""
                st.session_state["questions_data"] = []
                st.session_state["interview_results_state"] = {} # ì´ˆê¸°í™”


# ì§ˆë¬¸ ë°ì´í„°ê°€ session_stateì— ìˆì„ ê²½ìš° ë©´ì ‘ UI í‘œì‹œ
if "questions_data" in st.session_state and st.session_state["questions_data"]:
    with st.expander("ğŸ§¾ AI ì‘ë‹µ ì›ë³¸ ë³´ê¸°"):
        st.code(st.session_state.get("questions_raw_output", "ì—†ìŒ"), language="markdown")

    st.header("3ï¸âƒ£ ì‹¤ì‹œê°„ ë©´ì ‘ ì§„í–‰ (ìŒì„± ë‹µë³€ ì¸ì‹)")
    st.warning("ì•„ë˜ ë§ˆì´í¬ ì•„ì´ì½˜ì€ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì‹œì‘/ì¤‘ì§€í•©ë‹ˆë‹¤. 'ìŒì„± ì¸ì‹ ì‹¤í–‰' ë²„íŠ¼ì€ ìŠ¤íŠ¸ë¦¼ì´ í™œì„±í™”ëœ ë™ì•ˆ ìˆ˜ì§‘ëœ ì˜¤ë””ì˜¤ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤.")


    # ë©´ì ‘ ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ session_state ì´ˆê¸°í™” (ì´ë¯¸ ìœ„ì—ì„œ í–ˆì§€ë§Œ, í˜¹ì‹œë‚˜ ë‹¤ì‹œ í™•ì¸)
    if "interview_results_state" not in st.session_state:
        st.session_state["interview_results_state"] = {}
    # í˜„ì¬ ì§ˆë¬¸ ë°ì´í„°ì˜ ìˆ˜ì™€ session_stateì˜ ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ì´ˆê¸°í™” (ìƒˆ ì§ˆë¬¸ ìƒì„± ì‹œ)
    if len(st.session_state["interview_results_state"]) // 2 != len(st.session_state["questions_data"]):
         st.session_state["interview_results_state"] = {}
         for i in range(len(st.session_state["questions_data"])):
              st.session_state["interview_results_state"][f"answer_{i}"] = ""
              st.session_state["interview_results_state"][f"comment_{i}"] = ""


    # WebRTC Audio Processor ì •ì˜
    # ê° ì§ˆë¬¸ë³„ ì˜¤ë””ì˜¤ë¥¼ ë¶„ë¦¬í•´ì„œ ì²˜ë¦¬í•˜ë ¤ë©´ ë” ë³µì¡í•œ ë¡œì§ì´ í•„ìš”
    # ì—¬ê¸°ì„œëŠ” WebRTC ìŠ¤íŠ¸ë¦¼ ìì²´ëŠ” í•˜ë‚˜ë¡œ ìœ ì§€í•˜ê³ , ë²„íŠ¼ í´ë¦­ ì‹œ ì „ì²´ ë˜ëŠ” íŠ¹ì • ì‹œì  ì˜¤ë””ì˜¤ ì²˜ë¦¬
    # í•˜ì§€ë§Œ, Streamlitì˜ Rerun íŠ¹ì„±ìƒ AudioProcessorBaseì˜ frames ë¦¬ìŠ¤íŠ¸ê°€ ë§¤ë²ˆ ì´ˆê¸°í™”ë˜ë¯€ë¡œ
    # ì˜¤ë””ì˜¤ë¥¼ ì§€ì†ì ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³  íŠ¹ì • ì‹œì ì— ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ êµ¬í˜„ì´ ë³µì¡í•¨.
    # ê°„ë‹¨í•˜ê²Œ í˜„ì¬ êµ¬í˜„ëœ ctx.audio_processor.framesë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì„ ë”°ë¥´ì§€ë§Œ,
    # ì‹¤ì œ ì‚¬ìš© ì‹œ ì˜¤ë””ì˜¤ ìˆ˜ì§‘ ë° ë³€í™˜ íƒ€ì´ë° ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŒì„ ì¸ì§€í•´ì•¼ í•¨.
    class InterviewAudioProcessor(AudioProcessorBase):
         def __init__(self) -> None:
             self.frames = []
             self._samples = [] # NumPy ë°°ì—´ í˜•íƒœë¡œ ìƒ˜í”Œ ì €ì¥

         def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
             # ì˜¤ë””ì˜¤ í”„ë ˆì„ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
             self.frames.append(frame)
             # NumPy ë°°ì—´ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë³„ë„ë¡œ ì €ì¥ (WAV íŒŒì¼ ìƒì„±ì— ìš©ì´)
             self._samples.append(frame.to_ndarray(format="s16le")) # s16le: 16ë¹„íŠ¸ Little Endian PCM

             # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê´€ë¦¬ë¥¼ ìœ„í•´ ì¼ì • í”„ë ˆì„/ìƒ˜í”Œ ì´ìƒ ìŒ“ì´ë©´ ì˜¤ë˜ëœ ê²ƒ ì‚­ì œ ê³ ë ¤ í•„ìš”
             # pass # í˜„ì¬ëŠ” ëª¨ë“  í”„ë ˆì„ì„ ìˆ˜ì§‘

             return frame

         def get_audio_samples(self) -> np.ndarray:
             """ìˆ˜ì§‘ëœ ì˜¤ë””ì˜¤ ìƒ˜í”Œì„ í•˜ë‚˜ì˜ NumPy ë°°ì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
             if not self._samples:
                  return np.array([], dtype=np.int16)
             return np.concatenate(self._samples, axis=1).T # ì±„ë„ì„ ë‘ ë²ˆì§¸ ì¶•ìœ¼ë¡œ í•©ì¹˜ê³  ì „ì¹˜ (ìƒ˜í”Œ ìˆ˜, ì±„ë„ ìˆ˜) í˜•íƒœ

         def clear_samples(self):
             """ìˆ˜ì§‘ëœ ì˜¤ë””ì˜¤ ìƒ˜í”Œì„ ë¹„ì›ë‹ˆë‹¤."""
             self.frames = []
             self._samples = []


    # WebRTC ìŠ¤íŠ¸ë¦¬ë¨¸ëŠ” í•œ ë²ˆë§Œ ì •ì˜
    webrtc_ctx = webrtc_streamer(
        key="interview_audio_stream",
        mode=WebRtcMode.SENDONLY, # ì˜¤ë””ì˜¤ë§Œ ì „ì†¡
        audio_receiver_size=2048, # ë¦¬ì‹œë²„ ë²„í¼ ì‚¬ì´ì¦ˆ ì¦ê°€
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
        media_stream_constraints={"audio": True, "video": False}, # ì˜¤ë””ì˜¤ë§Œ ìš”ì²­
        audio_processor_factory=InterviewAudioProcessor, # ì»¤ìŠ¤í…€ ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ ì‚¬ìš©
    )
    st.info("ğŸ‘† ë©´ì ‘ ì‹œì‘/ì¢…ë£Œ ì‹œ ìœ„ ë§ˆì´í¬ ì•„ì´ì½˜ì„ í´ë¦­í•˜ì„¸ìš”.")

    # ê° ì§ˆë¬¸ë³„ UI ìƒì„±
    for idx, q in enumerate(st.session_state["questions_data"]):
        st.markdown(f"#### â“ ì§ˆë¬¸ {idx+1}")
        st.markdown(f"**{q['question']}**")
        st.markdown(f"ğŸ“Œ ì§ˆë¬¸ ì˜ë„: _{q['intent']}_")

        # ìŒì„± ì¸ì‹ ë²„íŠ¼
        # ì´ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì˜¤ë””ì˜¤ë¥¼ ë³€í™˜
        if st.button(f"ğŸ§  ì§ˆë¬¸ {idx+1} - ìŒì„± ì¸ì‹ ì‹¤í–‰", key=f"transcribe_btn_{idx}"):
             if webrtc_ctx.audio_processor:
                 # ì˜¤ë””ì˜¤ ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°
                 audio_samples = webrtc_ctx.audio_processor.get_audio_samples()

                 if audio_samples.size > 0:
                     with st.spinner(f"ì§ˆë¬¸ {idx+1} ë‹µë³€ ì¸ì‹ ì¤‘..."):
                         try:
                             # ì„ì‹œ WAV íŒŒì¼ë¡œ ì €ì¥ (WAV í—¤ë” í¬í•¨)
                             with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                                 temp_wav_path = f.name
                                 # SciPyë¥¼ ì‚¬ìš©í•˜ì—¬ WAV íŒŒì¼ ì“°ê¸°
                                 # ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì •ë³´ í•„ìš” (av.AudioFrameì—ì„œ ì–»ì„ ìˆ˜ ìˆìŒ)
                                 # AudioProcessorBaseì—ì„œ ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¥¼ ì €ì¥í•˜ê±°ë‚˜, ì²« í”„ë ˆì„ì—ì„œ ì–»ì–´ì•¼ í•¨
                                 # ê°„í¸í•˜ê²Œ 44100Hzë¡œ ê°€ì • (ì‹¤ì œ ìŠ¤íŠ¸ë¦¼ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¥¼ í™•ì¸í•˜ê³  ì ìš© í•„ìš”)
                                 sample_rate = 44100 # ì‹¤ì œ ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¡œ ë³€ê²½í•´ì•¼ í•¨!
                                 scipy.io.wavfile.write(temp_wav_path, sample_rate, audio_samples)

                             # Whisper ëª¨ë¸ë¡œ ë³€í™˜
                             result = whisper_model.transcribe(temp_wav_path, language="ko") # í•œêµ­ì–´ ì§€ì •
                             transcribed_text = result["text"]

                             # session_stateì— ê²°ê³¼ ì €ì¥ ë° UI ì—…ë°ì´íŠ¸
                             st.session_state["interview_results_state"][f"answer_{idx}"] = transcribed_text
                             st.text_area(f"ğŸ¤ ì§€ì›ì ë‹µë³€ {idx+1}", value=transcribed_text, key=f"answer_field_{idx}") # UI ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°

                             st.success(f"âœ… ì§ˆë¬¸ {idx+1} ì¸ì‹ ì™„ë£Œ!")

                             # ì¸ì‹ í›„ í˜„ì¬ê¹Œì§€ ìŒ“ì¸ ì˜¤ë””ì˜¤ë¥¼ ë¹„ìš¸ì§€ ì„ íƒ ê°€ëŠ¥
                             # webrtc_ctx.audio_processor.clear_samples() # í•„ìš”ì‹œ í™œì„±í™”

                         except Exception as e:
                             st.error(f"ğŸ˜¥ ì§ˆë¬¸ {idx+1} ë‹µë³€ ì¸ì‹ ì˜¤ë¥˜: {e}")
                             import traceback
                             st.error(traceback.format_exc()) # ë””ë²„ê¹…ì„ ìœ„í•´ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥

                         finally:
                              # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                              if 'temp_wav_path' in locals() and tempfile.exists(temp_wav_path):
                                   tempfile.remove(temp_wav_path)

                 else:
                      st.warning(f"â“ ì§ˆë¬¸ {idx+1} ë‹µë³€ ì˜¤ë””ì˜¤ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì•„ì´ì½˜ì„ í´ë¦­í•˜ì—¬ ìŠ¤íŠ¸ë¦¼ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")

        # ì§€ì›ì ë‹µë³€ ìˆ˜ë™ ì…ë ¥/í™•ì¸ í¼ (session_state ê°’ìœ¼ë¡œ ì´ˆê¸°í™” ë° ì—…ë°ì´íŠ¸)
        # keyë¥¼ ì‚¬ìš©í•˜ì—¬ session_state['interview_results_state'][f"answer_{idx}"]ì™€ ì—°ë™
        st.session_state["interview_results_state"][f"answer_{idx}"] = st.text_area(
            f"ğŸ¤ ì§€ì›ì ë‹µë³€ {idx+1}",
            value=st.session_state["interview_results_state"].get(f"answer_{idx}", ""),
            key=f"answer_field_{idx}" # keyë¥¼ ì‚¬ìš©í•˜ì—¬ session_state['interview_results_state'][f"answer_{idx}"]ì— ìë™ ì €ì¥
        )

        # ë©´ì ‘ê´€ ì˜ê²¬ ì…ë ¥ í¼ (session_state ê°’ìœ¼ë¡œ ì´ˆê¸°í™” ë° ì—…ë°ì´íŠ¸)
        # keyë¥¼ ì‚¬ìš©í•˜ì—¬ session_state['interview_results_state'][f"comment_{idx}"]ì™€ ì—°ë™
        st.session_state["interview_results_state"][f"comment_{idx}"] = st.text_area(
            f"ğŸ“ ë©´ì ‘ê´€ ì˜ê²¬ {idx+1}",
            value=st.session_state["interview_results_state"].get(f"comment_{idx}", ""),
            key=f"comment_field_{idx}" # keyë¥¼ ì‚¬ìš©í•˜ì—¬ session_state['interview_results_state'][f"comment_{idx}"]ì— ìë™ ì €ì¥
        )

        st.markdown("---")

    # ë©´ì ‘ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    # session_stateì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ CSV ìƒì„±
    if st.button("â¬‡ï¸ ë©´ì ‘ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", key="download_button"):
        # session_stateì—ì„œ í˜„ì¬ ì§ˆë¬¸ë“¤ì— í•´ë‹¹í•˜ëŠ” ê²°ê³¼ ë°ì´í„° ì¶”ì¶œ
        final_interview_results = []
        for idx, q in enumerate(st.session_state["questions_data"]):
             final_interview_results.append({
                 "ì§ˆë¬¸ë²ˆí˜¸": idx + 1,
                 "ì§ˆë¬¸": q["question"],
                 "ì§ˆë¬¸ ì˜ë„": q["intent"],
                 "ì§€ì›ì ë‹µë³€": st.session_state["interview_results_state"].get(f"answer_{idx}", ""),
                 "ë©´ì ‘ê´€ ì˜ê²¬": st.session_state["interview_results_state"].get(f"comment_{idx}", "")
                 # AI í‰ê°€ ê²°ê³¼ í•„ë“œëŠ” ì—¬ê¸°ì— ì¶”ê°€ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
             })

        if final_interview_results:
            df = pd.DataFrame(final_interview_results)
            csv = df.to_csv(index=False).encode('utf-8') # í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ utf-8ë¡œ ì¸ì½”ë”©
            st.download_button(
                "ğŸ“¥ CSV ì €ì¥í•˜ê¸°",
                csv,
                "interview_results.csv",
                "text/csv",
                key='csv_download_button'
            )
            st.success("CSV íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("ë‹¤ìš´ë¡œë“œí•  ë©´ì ‘ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

else:
    # ì§ˆë¬¸ ë°ì´í„°ê°€ ì—†ì„ ë•Œ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ë¹„í™œì„±í™” ë˜ëŠ” ìˆ¨ê¹€
    pass # ì§ˆë¬¸ ìƒì„± ì „ì—ëŠ” ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í‘œì‹œí•˜ì§€ ì•ŠìŒ