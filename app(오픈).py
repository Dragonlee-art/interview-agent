import streamlit as st
st.set_page_config(page_title="AI ë©´ì ‘ ì—ì´ì „íŠ¸", layout="wide")

import pandas as pd
import whisper
import av
import tempfile
import pdfplumber
import re
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode
from openai import OpenAI

client = OpenAI(api_key=st.secrets["openai"]["api_key"])

@st.cache_resource
def load_whisper_model():
    return whisper.load_model("base")

model = load_whisper_model()

st.title("ğŸ¤ AI ë©´ì ‘ ì—ì´ì „íŠ¸")
st.info("ì§€ì›ì ì´ë ¥ì„œë¥¼ ë§¥ë½ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ê³ , PDF ê¸°ë°˜ ì§ˆë¬¸ì„ ìƒì„±í•˜ë©°, ìŒì„± ì‘ë‹µê¹Œì§€ ê¸°ë¡í•©ë‹ˆë‹¤.")

st.header("1ï¸âƒ£ íšŒì‚¬ ì •ë³´ ë° ì´ë ¥ì„œ ì—…ë¡œë“œ")
col1, col2 = st.columns(2)

with col1:
    core_pdfs = st.file_uploader("ğŸ¢ í•µì‹¬ ê°€ì¹˜ (PDF)", type=["pdf"], accept_multiple_files=True)
    persona_pdfs = st.file_uploader("ğŸ‘¤ ì¸ì¬ìƒ (PDF)", type=["pdf"], accept_multiple_files=True)

with col2:
    jd_pdfs = st.file_uploader("ğŸ“ ì§ë¬´ ê¸°ìˆ ì„œ (PDF)", type=["pdf"], accept_multiple_files=True)
    resume_pdfs = st.file_uploader("ğŸ“„ ì§€ì›ì ì´ë ¥ì„œ (PDF)", type=["pdf"], accept_multiple_files=True)

def extract_pdf_text(files):
    result = ""
    if files:
        for uploaded_file in files:
            with pdfplumber.open(uploaded_file) as pdf:
                result += "\n".join([page.extract_text() or "" for page in pdf.pages])
    return result

def truncate_text(text, max_chars=4000):
    return text[:max_chars]

st.header("2ï¸âƒ£ ì§ˆë¬¸ ìë™ ìƒì„± (AI ê¸°ë°˜)")
num_questions = st.slider("ì§ˆë¬¸ ìˆ˜", 1, 10, 3)

if st.button("ğŸš€ ì§ˆë¬¸ ìƒì„±"):
    core_text = truncate_text(extract_pdf_text(core_pdfs))
    persona_text = truncate_text(extract_pdf_text(persona_pdfs))
    jd_text = truncate_text(extract_pdf_text(jd_pdfs))
    resume_text = truncate_text(extract_pdf_text(resume_pdfs))

    if not all([core_text, persona_text, jd_text, resume_text]):
        st.warning("ëª¨ë“  PDF í•­ëª©ì„ ì—…ë¡œë“œí•´ì•¼ ì§ˆë¬¸ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        prompt = f"""
ë‹¹ì‹ ì€ ê¸°ì—…ì˜ ì‹œë‹ˆì–´ ì¸ì‚¬ë‹´ë‹¹ìì´ë©°, AI ë©´ì ‘ ì§ˆë¬¸ ìë™ ìƒì„± ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

ì•„ë˜ 4ê°€ì§€ ë¬¸ì„œë¥¼ ì œê³µí•©ë‹ˆë‹¤:
1. íšŒì‚¬ì˜ í•µì‹¬ ê°€ì¹˜ (Core Values)
2. ì±„ìš© ì¸ì¬ìƒ (Ideal Persona)
3. ì§ë¬´ ê¸°ìˆ ì„œ (Job Description)
4. ì§€ì›ìì˜ ì´ë ¥ì„œ (Resume)

ë‹¹ì‹ ì˜ ì—­í• ì€ ì´ë ¥ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ê²€ì¦ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤:

---

ğŸ“Œ ì§ˆë¬¸ ì„¤ê³„ ì§€ì¹¨:

1. **ê²½í—˜ ê¸°ë°˜ ì§ˆë¬¸**ì„ ìƒì„±í•˜ì„¸ìš”. ë°˜ë“œì‹œ ì§€ì›ìì˜ ê³¼ê±° ê²½í—˜ì´ë‚˜ í”„ë¡œì íŠ¸, í™œë™ì„ ê¸°ë°˜ìœ¼ë¡œ ë¬¼ì–´ì•¼ í•©ë‹ˆë‹¤.
2. ì§ˆë¬¸ì€ **í•µì‹¬ ê°€ì¹˜**, **ì¸ì¬ìƒ**, **ì§ë¬´ ìš”ê±´** ì¤‘ í•˜ë‚˜ ì´ìƒì— ëŒ€í•´ ì§€ì›ìì˜ ì í•©ì„±ì„ í™•ì¸í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
3. ì´ë ¥ì„œì˜ íŠ¹ì • ë¬¸ì¥, ê²½ë ¥ ë‚´ìš©, í‚¤ì›Œë“œ ë“±ì„ í™œìš©í•˜ì—¬ **êµì°¨ ë¶„ì„**í•œ ê²°ê³¼ë¡œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.4. í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:

ê° ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”:
===
Q. [ì§ˆë¬¸ ë‚´ìš©]
ì§ˆë¬¸ ì˜ë„: [ê²€ì¦ í¬ì¸íŠ¸]
===

ì§ˆë¬¸ ìˆ˜: {num_questions}ê°œ
"""
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt + "\n\ní•µì‹¬ ê°€ì¹˜:\n" + core_text + "\n\nì¸ì¬ìƒ:\n" + persona_text + "\n\nJD:\n" + jd_text + "\n\nì´ë ¥ì„œ:\n" + resume_text}],
            temperature=0.7,
            max_tokens=1000
        )
        output = response.choices[0].message.content
        st.session_state["questions"] = output
        st.success("ì§ˆë¬¸ ìƒì„± ì™„ë£Œ")

if "questions" in st.session_state and st.session_state["questions"] != "":
    with st.expander("ğŸ§¾ GPT ì‘ë‹µ ì›ë³¸ ë³´ê¸°"):
        st.code(st.session_state.get("questions", "ì—†ìŒ"), language="markdown")

    st.header("3ï¸âƒ£ ì‹¤ì‹œê°„ ë©´ì ‘ ì§„í–‰ (ìŒì„± ë‹µë³€ ì¸ì‹)")

    blocks = st.session_state["questions"].split("===")
    questions_data = []
    for b in blocks:
        lines = b.strip().split("\n")
        q_line = next((l for l in lines if re.search(r"Q[.:]", l)), "")
        intent_line = next((l for l in lines if "ì§ˆë¬¸ ì˜ë„" in l), "")
        if q_line:
            questions_data.append({
                "question": re.sub(r"^.*Q[.:]", "", q_line).strip(),
                "intent": intent_line.replace("ì§ˆë¬¸ ì˜ë„:", "").strip()
            })

    class Recorder(AudioProcessorBase):
        def __init__(self) -> None:
            self.frames = []

        def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
            self.frames.append(frame)
            return frame

    interview_results = []

    for idx, q in enumerate(questions_data):
        st.markdown(f"### â“ ì§ˆë¬¸ {idx+1}")
        st.markdown(f"**{q['question']}**")
        st.markdown(f"ğŸ“Œ ì§ˆë¬¸ ì˜ë„: _{q['intent']}_")

        ctx = webrtc_streamer(
            key=f"webrtc_{idx}",
            mode=WebRtcMode.SENDONLY,
            audio_receiver_size=1024,
            rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
            media_stream_constraints={"audio": True, "video": False},
            audio_processor_factory=Recorder,
        )

        if f"answer_{idx}" not in st.session_state:
            st.session_state[f"answer_{idx}"] = ""

        if ctx.audio_processor and len(ctx.audio_processor.frames) > 0:
            if st.button(f"ğŸ§  ì§ˆë¬¸ {idx+1} - ìŒì„± ì¸ì‹ ì‹¤í–‰"):
                with st.spinner("Whisperê°€ ì¸ì‹ ì¤‘..."):
                    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                        audio = b''.join([frame.to_ndarray().tobytes() for frame in ctx.audio_processor.frames])
                        f.write(audio)
                        audio_path = f.name
                    result = model.transcribe(audio_path, language="ko")
                    st.session_state[f"answer_{idx}"] = result["text"]
                    st.success("ğŸ¯ ì¸ì‹ ì™„ë£Œ!")

        st.text_input("ğŸ¤ ì§€ì›ì ë‹µë³€", value=st.session_state[f"answer_{idx}"], key=f"answer_field_{idx}")
        comment_key = f"comment_{idx}"
        st.text_area("ğŸ“ ë©´ì ‘ê´€ ì˜ê²¬", key=comment_key)

        interview_results.append({
            "ì§ˆë¬¸ë²ˆí˜¸": idx + 1,
            "ì§ˆë¬¸": q["question"],
            "ì§ˆë¬¸ ì˜ë„": q["intent"],
            "ì§€ì›ì ë‹µë³€": st.session_state[f"answer_{idx}"],
            "ë©´ì ‘ê´€ ì˜ê²¬": st.session_state.get(comment_key, "")
        })

        st.markdown("---")

    if st.button("â¬‡ï¸ ë©´ì ‘ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ"):
        df = pd.DataFrame(interview_results)
        csv = df.to_csv(index=False)
        st.download_button("ğŸ“¥ CSV ì €ì¥í•˜ê¸°", csv, "interview_results.csv", mime="text/csv")
